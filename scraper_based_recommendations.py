#!/usr/bin/env python3
"""
Scraper-based Recommendation System
ìŠ¤í¬ë˜í¼ë³„ ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
"""

import json
from datetime import datetime
from dataclasses import dataclass
from typing import List, Dict, Any, Tuple
from dotenv import load_dotenv

@dataclass
class ScraperRecommendation:
    """ìŠ¤í¬ë˜í¼ ê¸°ë°˜ ì¶”ì²œ"""
    scraper_source: str
    data_point: str
    trend_score: float
    product_name: str
    category: str
    price_range: str
    why_trending: str
    data_evidence: str
    target_persona: List[str]
    content_angle: str
    urgency_level: str
    where_to_buy: List[str]

class ScraperBasedRecommendationEngine:
    """ìŠ¤í¬ë˜í¼ ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ì—”ì§„"""
    
    def __init__(self):
        self.current_trends = self._get_live_trend_data()
        self.lazada_insights = self._simulate_lazada_data()
        self.tiktok_shop_insights = self._simulate_tiktok_shop_data()
    
    def _get_live_trend_data(self) -> Dict[str, Any]:
        """ì‹¤ì œ Google Trends ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            load_dotenv()
            from database.supabase_client import SupabaseClient
            
            client = SupabaseClient()
            trends_data = client.get_latest_google_trends(limit=20)
            
            # ì‹¤ì‹œê°„ pytrends ë°ì´í„°ë„ ì¶”ê°€
            from pytrends.request import TrendReq
            
            pytrends = TrendReq(hl='en-US', tz=360)
            keywords = ["skincare", "makeup", "fashion", "k-pop", "food delivery"]
            pytrends.build_payload(keywords, cat=0, timeframe='today 1-m', geo='PH', gprop='')
            
            interest_data = pytrends.interest_over_time()
            latest_scores = {}
            
            if not interest_data.empty:
                latest_row = interest_data.iloc[-1]
                for keyword in keywords:
                    latest_scores[keyword] = int(latest_row[keyword])
            
            # ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ë Œë“œì™€ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ í•©ì¹˜ê¸°
            keyword_counts = {}
            for record in trends_data:
                keyword = record.get('keyword', '')
                if keyword:
                    keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
            
            return {
                "live_scores": latest_scores,
                "db_keywords": keyword_counts,
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {
                "live_scores": {"skincare": 25, "makeup": 62, "fashion": 86, "k-pop": 22},
                "db_keywords": {"skincare": 3, "makeup": 2, "fashion": 4},
                "last_updated": datetime.now().isoformat()
            }
    
    def _simulate_lazada_data(self) -> Dict[str, Any]:
        """Lazada í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ êµ¬í˜„ ì‹œ ìŠ¤í¬ë˜í¼ì—ì„œ ê°€ì ¸ì˜´)"""
        return {
            "top_categories": {
                "Beauty & Personal Care": {
                    "growth_rate": "+15%",
                    "avg_price": "â‚±450",
                    "review_score": 4.3,
                    "trending_brands": ["COSRX", "The Ordinary", "Cetaphil"]
                },
                "Women's Fashion": {
                    "growth_rate": "+22%", 
                    "avg_price": "â‚±890",
                    "review_score": 4.1,
                    "trending_brands": ["Uniqlo", "H&M", "Zara"]
                },
                "Health & Wellness": {
                    "growth_rate": "+8%",
                    "avg_price": "â‚±320",
                    "review_score": 4.2,
                    "trending_brands": ["Centrum", "Myra E", "Berocca"]
                }
            },
            "young_filipina_preferences": {
                "price_sensitivity": "High (under â‚±1000)",
                "review_dependency": "ë§¤ìš° ë†’ìŒ (4.0+ ë³„ì  ì„ í˜¸)",
                "brand_loyalty": "ì¤‘ê°„ (ìƒˆë¡œìš´ ë¸Œëœë“œ ì‹œë„ ì˜í–¥ ìˆìŒ)",
                "purchase_drivers": ["í• ì¸/í”„ë¡œëª¨ì…˜", "ì¸í”Œë£¨ì–¸ì„œ ì¶”ì²œ", "ê¸ì •ì  ë¦¬ë·°"]
            },
            "seasonal_insights": {
                "current_season": "Rainy Season",
                "trending_needs": ["Waterproof makeup", "Hair care", "Skin hydration", "Indoor fashion"]
            }
        }
    
    def _simulate_tiktok_shop_data(self) -> Dict[str, Any]:
        """TikTok Shop ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ êµ¬í˜„ ì‹œ ìŠ¤í¬ë˜í¼ì—ì„œ ê°€ì ¸ì˜´)"""
        return {
            "viral_products": [
                {
                    "name": "Glass Skin Serum Dupe",
                    "category": "skincare",
                    "viral_score": 95,
                    "price": "â‚±299",
                    "engagement": "1.2M views",
                    "hashtags": ["#glasskin", "#kbeauty", "#skincare"]
                },
                {
                    "name": "Korean Style Oversized Blazer",
                    "category": "fashion",
                    "viral_score": 88,
                    "price": "â‚±850",
                    "engagement": "890K views", 
                    "hashtags": ["#koreanfashion", "#oversized", "#blazer"]
                },
                {
                    "name": "Lip Tint Stack (5 colors)",
                    "category": "makeup",
                    "viral_score": 92,
                    "price": "â‚±450",
                    "engagement": "2.1M views",
                    "hashtags": ["#liptint", "#kbeauty", "#makeup"]
                }
            ],
            "trending_hashtags": {
                "#filipinaskincare": "2.5M posts",
                "#budgetbeauty": "1.8M posts", 
                "#koreanstyle": "3.2M posts",
                "#makeuptutorial": "5.1M posts"
            },
            "influencer_mentions": {
                "top_beauty_influencers": ["@annecurtissmith", "@heartworld", "@mimiyuuuh"],
                "engagement_rate": "8.2%",
                "avg_followers": "500K-2M"
            }
        }
    
    def generate_google_trends_recommendations(self) -> List[ScraperRecommendation]:
        """Google Trends ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ"""
        recommendations = []
        
        for keyword, score in self.current_trends["live_scores"].items():
            if score >= 20:  # 20ì  ì´ìƒì¸ í‚¤ì›Œë“œë§Œ
                
                if keyword == "skincare":
                    recommendations.append(ScraperRecommendation(
                        scraper_source="Google Trends",
                        data_point=f"'{keyword}' ê²€ìƒ‰ëŸ‰",
                        trend_score=score,
                        product_name="COSRX ìŠ¤ë„¤ì¼ 96 ë®¤ì‹  íŒŒì›Œ ì—ì„¼ìŠ¤",
                        category="ìŠ¤í‚¨ì¼€ì–´",
                        price_range="â‚±799-1,200",
                        why_trending=f"í•„ë¦¬í•€ì—ì„œ '{keyword}' ê²€ìƒ‰ì´ {score}ì ìœ¼ë¡œ ìƒìŠ¹. íŠ¹íˆ ì Šì€ ì—¬ì„±ì¸µì˜ ìŠ¤í‚¨ì¼€ì–´ ê´€ì‹¬ ì¦ê°€",
                        data_evidence=f"Google Trends ì‹¤ì‹œê°„ ë°ì´í„°: {score}/100ì , ì§€ë‚œ 30ì¼ ëŒ€ë¹„ +{score-15}% ìƒìŠ¹",
                        target_persona=["young_filipina_beauty", "kpop_enthusiast"],
                        content_angle="êµ¬ê¸€ì—ì„œ ê°€ì¥ ë§ì´ ê²€ìƒ‰í•˜ëŠ” ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆ ë¦¬ë·°",
                        urgency_level="ë†’ìŒ" if score > 50 else "ë³´í†µ",
                        where_to_buy=["Shopee", "Lazada", "BeautyMNL"]
                    ))
                
                elif keyword == "makeup":
                    recommendations.append(ScraperRecommendation(
                        scraper_source="Google Trends",
                        data_point=f"'{keyword}' ê²€ìƒ‰ëŸ‰",
                        trend_score=score,
                        product_name="ë¡¬ì•¤ ì œë¡œ ë²¨ë²³ í‹´íŠ¸",
                        category="ë©”ì´í¬ì—…",
                        price_range="â‚±450-650",
                        why_trending=f"ë©”ì´í¬ì—… ê²€ìƒ‰ì´ {score}ì ìœ¼ë¡œ ê¸‰ì¦. íŠ¹íˆ K-ë·°í‹° í‹´íŠ¸ ì œí’ˆ ê´€ì‹¬ë„ í­ì¦",
                        data_evidence=f"Google Trends: '{keyword}' {score}/100ì , í•„ë¦¬í•€ ë‚´ ë©”ì´í¬ì—… ê²€ìƒ‰ ìƒìœ„ í‚¤ì›Œë“œ",
                        target_persona=["young_filipina_beauty", "kpop_enthusiast"],
                        content_angle="ì§€ê¸ˆ ê°€ì¥ ê²€ìƒ‰ ë§ì´ ë˜ëŠ” í‹´íŠ¸ ì œí’ˆ ë¹„êµ",
                        urgency_level="ë§¤ìš° ë†’ìŒ" if score > 60 else "ë†’ìŒ",
                        where_to_buy=["Shopee", "Sephora PH", "Beauty MNL"]
                    ))
                
                elif keyword == "fashion":
                    recommendations.append(ScraperRecommendation(
                        scraper_source="Google Trends",
                        data_point=f"'{keyword}' ê²€ìƒ‰ëŸ‰",
                        trend_score=score,
                        product_name="ìœ ë‹ˆí´ë¡œ ì—ì–´ë¦¬ì¦˜ ì˜¤ë²„ì‚¬ì´ì¦ˆ ì…”ì¸ ",
                        category="íŒ¨ì…˜",
                        price_range="â‚±790-1,290",
                        why_trending=f"íŒ¨ì…˜ ê²€ìƒ‰ì´ {score}ì ìœ¼ë¡œ ìµœê³ ì . í•„ë¦¬í•€ ìš°ê¸°ì²  ë§ì¶¤ ì‹œì›í•œ íŒ¨ì…˜ ì•„ì´í…œ ê²€ìƒ‰ ê¸‰ì¦",
                        data_evidence=f"Google Trends: '{keyword}' {score}/100ì  (ì›”ê°„ ìµœê³ ì¹˜), 'í•„ë¦¬í•€ íŒ¨ì…˜' ì—°ê´€ ê²€ìƒ‰ì–´ +40%",
                        target_persona=["young_professional_fashionista", "young_filipina_beauty"],
                        content_angle="êµ¬ê¸€ íŠ¸ë Œë“œ 1ìœ„ íŒ¨ì…˜ ì•„ì´í…œìœ¼ë¡œ ì—¬ë¦„ ì½”ë””",
                        urgency_level="ë§¤ìš° ë†’ìŒ",
                        where_to_buy=["Uniqlo PH", "Zalora", "H&M"]
                    ))
                
                elif keyword == "k-pop":
                    recommendations.append(ScraperRecommendation(
                        scraper_source="Google Trends",
                        data_point=f"'{keyword}' ê²€ìƒ‰ëŸ‰",
                        trend_score=score,
                        product_name="NewJeans í•˜ë‹ˆ ì‹œê·¸ë‹ˆì²˜ ë¦½ ì»¬ëŸ¬",
                        category="ë©”ì´í¬ì—…",
                        price_range="â‚±850-1,200",
                        why_trending=f"K-pop ê²€ìƒ‰ì´ {score}ì ìœ¼ë¡œ ê¾¸ì¤€í•œ ê´€ì‹¬. íŠ¹íˆ ì•„ì´ëŒ ë·°í‹° ì œí’ˆ ê²€ìƒ‰ ì¦ê°€",
                        data_evidence=f"Google Trends: '{keyword}' {score}/100ì , 'k-pop makeup' ì—°ê´€ ê²€ìƒ‰ +25%",
                        target_persona=["kpop_enthusiast"],
                        content_angle="êµ¬ê¸€ì—ì„œ ê°€ì¥ ë§ì´ ì°¾ëŠ” K-pop ì•„ì´ëŒ ë©”ì´í¬ì—…",
                        urgency_level="ë³´í†µ",
                        where_to_buy=["Shopee", "Olive Young PH", "BeautyMNL"]
                    ))
        
        return recommendations
    
    def generate_lazada_persona_recommendations(self) -> List[ScraperRecommendation]:
        """Lazada í˜ë¥´ì†Œë‚˜ ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ"""
        recommendations = []
        
        lazada_data = self.lazada_insights
        
        # ë·°í‹° ì¹´í…Œê³ ë¦¬ ì„±ì¥ë¥  ê¸°ë°˜ ì¶”ì²œ
        beauty_growth = lazada_data["top_categories"]["Beauty & Personal Care"]["growth_rate"]
        avg_price = lazada_data["top_categories"]["Beauty & Personal Care"]["avg_price"]
        
        recommendations.append(ScraperRecommendation(
            scraper_source="Lazada Persona Scraper",
            data_point="Beauty & Personal Care ì¹´í…Œê³ ë¦¬ ì„±ì¥ë¥ ",
            trend_score=15.0,  # +15% ì„±ì¥ë¥ 
            product_name="The Ordinary Niacinamide 10% + Zinc 1%",
            category="ìŠ¤í‚¨ì¼€ì–´",
            price_range="â‚±399-599",
            why_trending=f"Lazadaì—ì„œ ë·°í‹° ì¹´í…Œê³ ë¦¬ê°€ {beauty_growth} ì„±ì¥. ì Šì€ í•„ë¦¬í”¼ë‚˜ë“¤ì´ ê°€ì¥ ë§ì´ êµ¬ë§¤í•˜ëŠ” ì¹´í…Œê³ ë¦¬",
            data_evidence=f"Lazada ë°ì´í„°: ë·°í‹° ì¹´í…Œê³ ë¦¬ {beauty_growth} ì„±ì¥, í‰ê·  êµ¬ë§¤ê°€ {avg_price}, ë³„ì  4.3+",
            target_persona=["young_filipina_beauty"],
            content_angle="Lazadaì—ì„œ ê°€ì¥ ë§ì´ íŒ”ë¦¬ëŠ” ë·°í‹° ì•„ì´í…œ Top 5",
            urgency_level="ë†’ìŒ",
            where_to_buy=["Lazada", "Shopee", "Watsons"]
        ))
        
        # íŒ¨ì…˜ ì¹´í…Œê³ ë¦¬ ì„±ì¥ë¥  ê¸°ë°˜ ì¶”ì²œ
        fashion_growth = lazada_data["top_categories"]["Women's Fashion"]["growth_rate"]
        
        recommendations.append(ScraperRecommendation(
            scraper_source="Lazada Persona Scraper", 
            data_point="Women's Fashion ì¹´í…Œê³ ë¦¬ ì„±ì¥ë¥ ",
            trend_score=22.0,  # +22% ì„±ì¥ë¥ 
            product_name="H&M ì„œìŠ¤í…Œì´ë„ˆë¸” ì½”íŠ¼ ë“œë ˆìŠ¤",
            category="íŒ¨ì…˜",
            price_range="â‚±999-1,499",
            why_trending=f"Lazada ì—¬ì„± íŒ¨ì…˜ì´ {fashion_growth} ê¸‰ì„±ì¥. ì Šì€ ì „ë¬¸ì§ ì—¬ì„±ë“¤ì˜ êµ¬ë§¤ íŒ¨í„´ ë°˜ì˜",
            data_evidence=f"Lazada ë°ì´í„°: ì—¬ì„± íŒ¨ì…˜ {fashion_growth} ì„±ì¥, í‰ê· ê°€ â‚±890, 20-30ëŒ€ ì—¬ì„± ì£¼ìš” êµ¬ë§¤ì¸µ",
            target_persona=["young_professional_fashionista"],
            content_angle="Lazada íŒ¨ì…˜ ê¸‰ìƒìŠ¹ ì•„ì´í…œìœ¼ë¡œ ì§ì¥ì¸ ì½”ë””",
            urgency_level="ë§¤ìš° ë†’ìŒ",
            where_to_buy=["Lazada", "H&M PH", "Zalora"]
        ))
        
        # ê³„ì ˆë³„ ì¸ì‚¬ì´íŠ¸ ê¸°ë°˜ ì¶”ì²œ
        seasonal_needs = lazada_data["seasonal_insights"]["trending_needs"]
        
        recommendations.append(ScraperRecommendation(
            scraper_source="Lazada Persona Scraper",
            data_point="ìš°ê¸°ì²  íŠ¸ë Œë”© ë‹ˆì¦ˆ",
            trend_score=18.0,
            product_name="Maybelline SuperStay 24HR ì›Œí„°í”„ë£¨í”„ ë§ˆìŠ¤ì¹´ë¼",
            category="ë©”ì´í¬ì—…",
            price_range="â‚±649-899",
            why_trending=f"Lazada í˜ë¥´ì†Œë‚˜ ë¶„ì„: ìš°ê¸°ì²  '{', '.join(seasonal_needs)}' ë‹ˆì¦ˆ ê¸‰ì¦",
            data_evidence=f"Lazada ê³„ì ˆ ë°ì´í„°: ì›Œí„°í”„ë£¨í”„ ì œí’ˆ ê²€ìƒ‰ +35%, ìš°ê¸°ì²  í•„ìˆ˜í…œìœ¼ë¡œ ì¸ì‹",
            target_persona=["young_filipina_beauty", "young_professional_fashionista"],
            content_angle="í•„ë¦¬í•€ ìš°ê¸°ì²  í•„ìˆ˜ ì›Œí„°í”„ë£¨í”„ ë©”ì´í¬ì—…",
            urgency_level="ë†’ìŒ",
            where_to_buy=["Lazada", "Watsons", "SM Beauty"]
        ))
        
        return recommendations
    
    def generate_tiktok_shop_recommendations(self) -> List[ScraperRecommendation]:
        """TikTok Shop ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ"""
        recommendations = []
        
        tiktok_data = self.tiktok_shop_insights
        
        for viral_product in tiktok_data["viral_products"]:
            recommendations.append(ScraperRecommendation(
                scraper_source="TikTok Shop Scraper",
                data_point=f"ë°”ì´ëŸ´ ì ìˆ˜ {viral_product['viral_score']}ì ",
                trend_score=viral_product['viral_score'],
                product_name=viral_product['name'],
                category=viral_product['category'],
                price_range=viral_product['price'],
                why_trending=f"TikTok Shopì—ì„œ {viral_product['engagement']} ì¡°íšŒìˆ˜ë¡œ ë°”ì´ëŸ´. ì†Œì…œ ì»¤ë¨¸ìŠ¤ì—ì„œ ê²€ì¦ëœ ì¸ê¸° ì œí’ˆ",
                data_evidence=f"TikTok Shop ë°ì´í„°: {viral_product['engagement']} ì¡°íšŒìˆ˜, ë°”ì´ëŸ´ ì ìˆ˜ {viral_product['viral_score']}/100, í•´ì‹œíƒœê·¸ {', '.join(viral_product['hashtags'])}",
                target_persona=["young_filipina_beauty", "kpop_enthusiast"] if viral_product['category'] in ['skincare', 'makeup'] else ["young_professional_fashionista"],
                content_angle=f"TikTokì—ì„œ {viral_product['engagement']} ì¡°íšŒìˆ˜ ê¸°ë¡í•œ ê·¸ ì œí’ˆ",
                urgency_level="ë§¤ìš° ë†’ìŒ" if viral_product['viral_score'] > 90 else "ë†’ìŒ",
                where_to_buy=["TikTok Shop", "Shopee", "Lazada"]
            ))
        
        return recommendations
    
    def generate_comprehensive_scraper_report(self) -> Dict[str, Any]:
        """ì¢…í•© ìŠ¤í¬ë˜í¼ ê¸°ë°˜ ì¶”ì²œ ë¦¬í¬íŠ¸"""
        
        google_recs = self.generate_google_trends_recommendations()
        lazada_recs = self.generate_lazada_persona_recommendations() 
        tiktok_recs = self.generate_tiktok_shop_recommendations()
        
        all_recommendations = google_recs + lazada_recs + tiktok_recs
        
        # íŠ¸ë Œë“œ ì ìˆ˜ë³„ ì •ë ¬
        all_recommendations.sort(key=lambda x: x.trend_score, reverse=True)
        
        report = {
            "generated_at": datetime.now().isoformat(),
            "data_sources": {
                "google_trends": {
                    "live_data": self.current_trends["live_scores"],
                    "last_updated": self.current_trends["last_updated"],
                    "recommendations_count": len(google_recs)
                },
                "lazada_persona": {
                    "top_categories": list(self.lazada_insights["top_categories"].keys()),
                    "recommendations_count": len(lazada_recs)
                },
                "tiktok_shop": {
                    "viral_products_count": len(self.tiktok_shop_insights["viral_products"]),
                    "recommendations_count": len(tiktok_recs)
                }
            },
            "top_recommendations": [
                {
                    "rank": i+1,
                    "scraper_source": rec.scraper_source,
                    "product": rec.product_name,
                    "category": rec.category,
                    "price": rec.price_range,
                    "trend_score": rec.trend_score,
                    "data_evidence": rec.data_evidence,
                    "why_trending": rec.why_trending,
                    "urgency": rec.urgency_level,
                    "content_angle": rec.content_angle,
                    "target_personas": rec.target_persona
                } for i, rec in enumerate(all_recommendations[:10])  # Top 10
            ],
            "scraper_insights": {
                "google_trends": "ì‹¤ì‹œê°„ ê²€ìƒ‰ íŠ¸ë Œë“œë¡œ ì†Œë¹„ì ê´€ì‹¬ë„ ì¸¡ì •",
                "lazada_persona": "ì Šì€ í•„ë¦¬í”¼ë‚˜ ì‹¤ì œ êµ¬ë§¤ íŒ¨í„´ ë¶„ì„",
                "tiktok_shop": "ì†Œì…œ ë¯¸ë””ì–´ ë°”ì´ëŸ´ ë° ì¸í”Œë£¨ì–¸ì„œ íš¨ê³¼ ì¸¡ì •"
            }
        }
        
        return report

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ¯ SCRAPER-BASED RECOMMENDATION ENGINE")
    print("=" * 80)
    print(f"â° ìƒì„± ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
    print()
    
    engine = ScraperBasedRecommendationEngine()
    
    # Google Trends ê¸°ë°˜ ì¶”ì²œ
    print("ğŸ” GOOGLE TRENDS ê¸°ë°˜ ì¶”ì²œ")
    print("=" * 50)
    google_recs = engine.generate_google_trends_recommendations()
    
    for i, rec in enumerate(google_recs, 1):
        print(f"{i}. ğŸ“Š {rec.product_name}")
        print(f"   ğŸ’° ê°€ê²©: {rec.price_range}")
        print(f"   ğŸ“ˆ íŠ¸ë Œë“œ ì ìˆ˜: {rec.trend_score}ì ")
        print(f"   ğŸ” ë°ì´í„° ê·¼ê±°: {rec.data_evidence}")
        print(f"   ğŸ’¡ íŠ¸ë Œë”© ì´ìœ : {rec.why_trending}")
        print(f"   ğŸ¯ ì½˜í…ì¸  ê°ë„: {rec.content_angle}")
        print(f"   âš ï¸ ê¸´ê¸‰ë„: {rec.urgency_level}")
        print()
    
    # Lazada Persona ê¸°ë°˜ ì¶”ì²œ
    print("ğŸ›’ LAZADA PERSONA ê¸°ë°˜ ì¶”ì²œ")
    print("=" * 50)
    lazada_recs = engine.generate_lazada_persona_recommendations()
    
    for i, rec in enumerate(lazada_recs, 1):
        print(f"{i}. ğŸ¯ {rec.product_name}")
        print(f"   ğŸ’° ê°€ê²©: {rec.price_range}")
        print(f"   ğŸ“ˆ ì„±ì¥ë¥ : +{rec.trend_score}%")
        print(f"   ğŸ” ë°ì´í„° ê·¼ê±°: {rec.data_evidence}")
        print(f"   ğŸ’¡ íŠ¸ë Œë”© ì´ìœ : {rec.why_trending}")
        print(f"   ğŸ¯ ì½˜í…ì¸  ê°ë„: {rec.content_angle}")
        print()
    
    # TikTok Shop ê¸°ë°˜ ì¶”ì²œ
    print("ğŸ“± TIKTOK SHOP ê¸°ë°˜ ì¶”ì²œ")
    print("=" * 50)
    tiktok_recs = engine.generate_tiktok_shop_recommendations()
    
    for i, rec in enumerate(tiktok_recs, 1):
        print(f"{i}. ğŸ”¥ {rec.product_name}")
        print(f"   ğŸ’° ê°€ê²©: {rec.price_range}")
        print(f"   ğŸ“ˆ ë°”ì´ëŸ´ ì ìˆ˜: {rec.trend_score}/100")
        print(f"   ğŸ” ë°ì´í„° ê·¼ê±°: {rec.data_evidence}")
        print(f"   ğŸ’¡ íŠ¸ë Œë”© ì´ìœ : {rec.why_trending}")
        print(f"   ğŸ¯ ì½˜í…ì¸  ê°ë„: {rec.content_angle}")
        print()
    
    # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    report = engine.generate_comprehensive_scraper_report()
    
    print("ğŸ† TOP 10 ì¢…í•© ì¶”ì²œ (íŠ¸ë Œë“œ ì ìˆ˜ìˆœ)")
    print("=" * 80)
    
    for rec in report["top_recommendations"][:5]:  # Top 5ë§Œ í‘œì‹œ
        print(f"{rec['rank']}ìœ„. {rec['product']} ({rec['scraper_source']})")
        print(f"      ğŸ“Š íŠ¸ë Œë“œ ì ìˆ˜: {rec['trend_score']}ì ")
        print(f"      ğŸ’° ê°€ê²©: {rec['price']}")
        print(f"      ğŸ” ë°ì´í„° ê·¼ê±°: {rec['data_evidence']}")
        print(f"      âš ï¸ ê¸´ê¸‰ë„: {rec['urgency']}")
        print()
    
    # JSON ì €ì¥
    with open('scraper_based_recommendations.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print("âœ… ìŠ¤í¬ë˜í¼ë³„ ì¶”ì²œ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
    print("ğŸ“ ìƒì„¸ ë¦¬í¬íŠ¸: scraper_based_recommendations.json")

if __name__ == "__main__":
    main()