"""
Lazada Philippines scraper as alternative to Shopee
ì‹¤ì œ Lazada ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìŠ¤í¬ë˜í¼
"""

import time
import random
import logging
import json
import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path
import sys

try:
    import undetected_chromedriver as uc
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
except ImportError as e:
    print(f"Selenium import error: {e}")

import requests
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from urllib.parse import quote, urljoin

# Add the project root to Python path for imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# Import SupabaseClient
try:
    from database.supabase_client import SupabaseClient
except ImportError:
    SupabaseClient = None
    print("âš ï¸ SupabaseClient not available - data will not be saved to database")

logger = logging.getLogger(__name__)


class LazadaScraper:
    """Lazada Philippines ìŠ¤í¬ë˜í¼ - Shopee ëŒ€ì•ˆ"""
    
    def __init__(
        self,
        base_url: str = "https://www.lazada.com.ph",
        use_undetected: bool = True
    ):
        self.base_url = base_url
        self.use_undetected = use_undetected
        self.driver = None
        self.user_agent = UserAgent()
        self.collection_date = datetime.now()
        self.wait_timeout = 30
        
        # Initialize Supabase client if available
        self.supabase_client = None
        if SupabaseClient:
            try:
                self.supabase_client = SupabaseClient()
                logger.info("âœ… Supabase client initialized")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to initialize Supabase client: {e}")
                self.supabase_client = None
    
    def _setup_driver(self):
        """Lazadaìš© í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •"""
        try:
            if self.use_undetected:
                options = uc.ChromeOptions()
                options.add_argument('--headless=new')
                options.add_argument('--no-sandbox')
                options.add_argument('--disable-dev-shm-usage')
                options.add_argument('--window-size=1366,768')
                
                # Philippines ì§€ì—­ ì„¤ì •
                user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
                options.add_argument(f'--user-agent={user_agent}')
                options.add_argument('--lang=en-PH,en-US,en')
                
                self.driver = uc.Chrome(options=options, version_main=None)
            
            # ìë™í™” ê°ì§€ ë°©ì§€
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.set_page_load_timeout(60)
            
            logger.info("âœ… Lazada WebDriver setup completed")
            
        except Exception as e:
            logger.error(f"âŒ Failed to setup Lazada WebDriver: {e}")
            raise
    
    def _wait_and_scroll(self, wait_time: int = 10):
        """í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° ë° ìŠ¤í¬ë¡¤ë§"""
        try:
            time.sleep(wait_time)
            
            # í˜ì´ì§€ ì™„ì „ ë¡œë“œ í™•ì¸
            WebDriverWait(self.driver, 30).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            
            # ìŠ¤í¬ë¡¤ë§ìœ¼ë¡œ ë™ì  ì½˜í…ì¸  ë¡œë“œ
            for i in range(3):
                scroll_position = (i + 1) * 800
                self.driver.execute_script(f"window.scrollTo(0, {scroll_position});")
                time.sleep(random.uniform(2, 4))
            
            # ë§¨ ìœ„ë¡œ ëŒì•„ê°€ê¸°
            self.driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(2)
            
            logger.info("âœ… Lazada page loading and scrolling completed")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Lazada scroll and wait warning: {e}")
    
    def _extract_lazada_products(self, product_elements: list) -> List[Dict[str, Any]]:
        """Lazada ì œí’ˆ ìš”ì†Œì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        products = []
        
        for i, element in enumerate(product_elements):
            try:
                product_data = {
                    'collection_date': self.collection_date.isoformat(),
                    'search_keyword': '',
                    'product_name': 'Unknown Product',
                    'product_url': '',
                    'price': '',
                    'seller_name': 'Unknown Seller',
                    'rating': None,
                    'review_count': None,
                    'image_url': '',
                    'platform': 'lazada'
                }
                
                # ì œí’ˆëª… ì¶”ì¶œ (Lazada íŠ¹í™”)
                name_selectors = [
                    '[data-qa-locator="product-item"] .title',
                    '.title-wrapper a',
                    '.product-card .title',
                    'a[title]',
                    '.item-title'
                ]
                
                for selector in name_selectors:
                    try:
                        name_element = element.find_element(By.CSS_SELECTOR, selector)
                        name = name_element.get_attribute('title') or name_element.text
                        if name and name.strip():
                            product_data['product_name'] = name.strip()
                            break
                    except:
                        continue
                
                # ê°€ê²© ì¶”ì¶œ (Lazada íŠ¹í™”)
                price_selectors = [
                    '.price-current',
                    '.currency',
                    '.price',
                    '[data-qa-locator="product-price"]'
                ]
                
                for selector in price_selectors:
                    try:
                        price_element = element.find_element(By.CSS_SELECTOR, selector)
                        price_text = price_element.text
                        if price_text and ('â‚±' in price_text or 'PHP' in price_text):
                            product_data['price'] = price_text.strip()
                            break
                    except:
                        continue
                
                # URL ì¶”ì¶œ
                try:
                    link_element = element.find_element(By.TAG_NAME, 'a')
                    href = link_element.get_attribute('href')
                    if href:
                        # ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
                        if href.startswith('/'):
                            href = self.base_url + href
                        product_data['product_url'] = href
                except:
                    pass
                
                # ì´ë¯¸ì§€ URL ì¶”ì¶œ
                try:
                    img_element = element.find_element(By.TAG_NAME, 'img')
                    img_src = img_element.get_attribute('src') or img_element.get_attribute('data-src')
                    if img_src:
                        product_data['image_url'] = img_src
                except:
                    pass
                
                # í‰ì  ì¶”ì¶œ
                rating_selectors = [
                    '.rating-star',
                    '.score-average',
                    '[data-qa-locator="product-rating"]'
                ]
                
                for selector in rating_selectors:
                    try:
                        rating_element = element.find_element(By.CSS_SELECTOR, selector)
                        rating_text = rating_element.text or rating_element.get_attribute('title')
                        rating_match = re.search(r'(\d+\.?\d*)', rating_text)
                        if rating_match:
                            product_data['rating'] = float(rating_match.group(1))
                            break
                    except:
                        continue
                
                # ìœ íš¨í•œ ì œí’ˆì¸ì§€ í™•ì¸
                if (product_data['product_name'] != 'Unknown Product' and 
                    product_data['product_url'] and 
                    'lazada.com.ph' in product_data['product_url']):
                    products.append(product_data)
                    logger.debug(f"âœ… Extracted Lazada product: {product_data['product_name'][:50]}...")
                
            except Exception as e:
                logger.debug(f"âš ï¸ Error extracting Lazada product {i}: {e}")
                continue
        
        return products
    
    def search_products(self, keyword: str, limit: int = 20) -> List[Dict[str, Any]]:
        """Lazada ì œí’ˆ ê²€ìƒ‰"""
        try:
            if not self.driver:
                self._setup_driver()
            
            # Lazada ê²€ìƒ‰ URL êµ¬ì„±
            search_url = f"{self.base_url}/catalog/?q={quote(keyword)}&sort=priceasc"
            
            logger.info(f"ğŸ” Lazada search for: {keyword}")
            logger.info(f"ğŸ“ Navigating to: {search_url}")
            
            # í˜ì´ì§€ ë¡œë“œ
            self.driver.get(search_url)
            
            # í˜ì´ì§€ ë¡œë“œ ë° ìŠ¤í¬ë¡¤ ëŒ€ê¸°
            self._wait_and_scroll(15)
            
            # ë´‡ ê°ì§€ í™•ì¸
            current_url = self.driver.current_url
            page_source = self.driver.page_source.lower()
            
            if 'captcha' in page_source or 'verify' in current_url:
                logger.warning("âŒ Lazada bot detection triggered")
                return []
            
            # Lazada ì œí’ˆ ìš”ì†Œ ì°¾ê¸°
            lazada_selectors = [
                '[data-qa-locator="product-item"]',
                '.product-item',
                '.item-box',
                '.product-card',
                '.list-item',
                '.item'
            ]
            
            products = []
            found_elements = []
            
            for selector in lazada_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if len(elements) >= 3:  # ì¶©ë¶„í•œ ìš”ì†Œë¥¼ ì°¾ì•˜ì„ ë•Œ
                        found_elements = elements
                        logger.info(f"âœ… Found {len(elements)} Lazada product elements using: {selector}")
                        break
                except Exception as e:
                    logger.debug(f"Lazada selector {selector} failed: {e}")
                    continue
            
            if not found_elements:
                logger.warning("âŒ No Lazada product elements found")
                return []
            
            # ì œí’ˆ ë°ì´í„° ì¶”ì¶œ
            products = self._extract_lazada_products(found_elements[:limit])
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œ ì„¤ì •
            for product in products:
                product['search_keyword'] = keyword
            
            logger.info(f"âœ… Successfully extracted {len(products)} real Lazada products for '{keyword}'")
            return products
            
        except Exception as e:
            logger.error(f"âŒ Error in Lazada product search: {e}")
            return []
    
    def get_trending_products(self, categories: List[str] = None, limit: int = 20, save_to_db: bool = True) -> List[Dict[str, Any]]:
        """Lazada íŠ¸ë Œë”© ì œí’ˆ ìˆ˜ì§‘"""
        try:
            logger.info("ğŸ“ˆ Lazada Trending Products collection starting...")
            
            if not categories:
                categories = [
                    "beauty",
                    "fashion", 
                    "electronics",
                    "skincare",
                    "phone",
                    "laptop"
                ]
            
            all_products = []
            products_per_category = max(1, limit // len(categories))
            
            for category in categories:
                try:
                    logger.info(f"ğŸ·ï¸ Searching Lazada trending: {category}")
                    products = self.search_products(category, limit=products_per_category)
                    
                    # íŠ¸ë Œë”© ë§ˆí‚¹
                    for product in products:
                        product['search_keyword'] = f"lazada_trending_{category}"
                        product['product_type'] = 'trending'
                        product['category'] = category
                        
                    all_products.extend(products)
                    
                    # ì¹´í…Œê³ ë¦¬ ê°„ ëŒ€ê¸°
                    time.sleep(random.uniform(3, 6))
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Error with Lazada category '{category}': {e}")
                    continue
            
            # ì¤‘ë³µ ì œê±°
            seen_urls = set()
            unique_products = []
            for product in all_products:
                url = product.get('product_url', '')
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    unique_products.append(product)
            
            final_products = unique_products[:limit]
            logger.info(f"âœ… Collected {len(final_products)} unique Lazada trending products")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            if save_to_db and final_products:
                self._save_to_supabase(final_products)
            
            return final_products
            
        except Exception as e:
            logger.error(f"âŒ Error collecting Lazada trending products: {e}")
            return []
    
    def _save_to_supabase(self, products: List[Dict[str, Any]]) -> bool:
        """Supabaseì— Lazada ì œí’ˆ ì €ì¥"""
        if not self.supabase_client:
            logger.warning("âš ï¸ Supabase client not available - skipping database save")
            return False
        
        if not products:
            logger.info("â„¹ï¸ No Lazada products to save to database")
            return True
        
        try:
            logger.info(f"ğŸ’¾ Saving {len(products)} real Lazada products to Supabase...")
            
            # ë°ì´í„° í¬ë§·íŒ… (Shopee í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶° ì €ì¥)
            formatted_products = []
            for product in products:
                formatted_product = {
                    'collection_date': product.get('collection_date', self.collection_date.isoformat()),
                    'search_keyword': product.get('search_keyword', 'unknown'),
                    'product_name': product.get('product_name', 'Unknown Product'),
                    'seller_name': product.get('seller_name', 'Lazada Seller'),
                    'price': self._extract_price_value(product.get('price', '0')),
                    'currency': 'PHP',
                    'rating': product.get('rating'),
                    'review_count': product.get('review_count'),
                    'product_url': product.get('product_url'),
                    'image_url': product.get('image_url'),
                    'category': product.get('category', product.get('product_type', 'general')),
                    'discount_info': {
                        'product_type': product.get('product_type'),
                        'original_keyword': product.get('search_keyword'),
                        'scrape_method': 'lazada_scraper',
                        'platform': 'lazada',
                        'is_real_data': True  # ì‹¤ì œ ë°ì´í„°ì„ì„ í‘œì‹œ
                    }
                }
                formatted_products.append(formatted_product)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (shopee_products í…Œì´ë¸”ì— ì €ì¥)
            success = self.supabase_client.insert_shopee_products(formatted_products)
            
            if success:
                logger.info(f"âœ… Successfully saved {len(formatted_products)} real Lazada products to Supabase")
                return True
            else:
                logger.error("âŒ Failed to save Lazada products to Supabase")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Error saving Lazada products to Supabase: {e}")
            return False
    
    def _extract_price_value(self, price_str: str) -> Optional[float]:
        """ê°€ê²© ë¬¸ìì—´ì—ì„œ ìˆ«ì ê°’ ì¶”ì¶œ"""
        try:
            if not price_str or price_str == 'N/A':
                return None
            # í†µí™” ê¸°í˜¸ì™€ ì‰¼í‘œ ì œê±°, ìˆ«ìë§Œ ì¶”ì¶œ
            import re
            price_match = re.search(r'[\d,]+\.?\d*', str(price_str).replace(',', ''))
            if price_match:
                return float(price_match.group())
            return None
        except:
            return None
    
    def close(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            self.driver = None
            logger.info("âœ… Lazada browser closed")


def main():
    """Lazada ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    scraper = LazadaScraper(use_undetected=True)
    
    try:
        print("ğŸ›’ Testing Lazada scraper...")
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        test_keyword = "skincare"
        products = scraper.search_products(test_keyword, limit=5)
        
        print(f"âœ… Found {len(products)} real Lazada products for '{test_keyword}'")
        
        if products:
            print("\nğŸ“¦ Real Lazada products found:")
            for i, product in enumerate(products):
                print(f"{i+1}. {product['product_name'][:50]}... - {product['price']}")
                print(f"   URL: {product['product_url'][:80]}...")
                print()
        
        return products
        
    except Exception as e:
        print(f"âŒ Error testing Lazada scraper: {e}")
        return []
    
    finally:
        scraper.close()


if __name__ == "__main__":
    main()